{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Face-Detection-in-Real-Time-Videos-OpenCV.ipynb","provenance":[{"file_id":"1HY6P2538SLxd4_GUWcvpNj0-0ySXTjmE","timestamp":1621064861534}],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMBwcv2YwsLT+yX9SWUU6ED"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"xoWB8tuRz4tk"},"source":["#**Face Detection in Real-Time Videos using OpenCV**"]},{"cell_type":"markdown","metadata":{"id":"m3EJ0wA2z_k7"},"source":["###**Import the necessary packages**"]},{"cell_type":"code","metadata":{"id":"2lpRB-1NzryW","executionInfo":{"status":"ok","timestamp":1621164607889,"user_tz":-330,"elapsed":779,"user":{"displayName":"Anand G","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBkVIo1RLhOwk1a6Mzmibi2s010DdEUBbH1fsFbvw=s64","userId":"09152808973096516443"}}},"source":["import cv2\n","import matplotlib.pyplot as plt"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JORPI1fV0RdK"},"source":["###**Get a Pre-Trained Classifier for face detection**\n","\n","OpenCV has a lot of pre-trained classifiers for face detection, eye detection etc...\n","We can get these `.xml` files from [GitHub.](https://github.com/opencv/opencv/tree/master/data/haarcascades)\n","\n","It has several positive and negative samples to train the model (Viola-Jones Algorithm)\n","\n","Here we are using the frontal face cascade classifier for detecting human front faced faces."]},{"cell_type":"code","metadata":{"id":"lt1l_FNw0Mt8","executionInfo":{"status":"ok","timestamp":1621164608413,"user_tz":-330,"elapsed":1279,"user":{"displayName":"Anand G","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBkVIo1RLhOwk1a6Mzmibi2s010DdEUBbH1fsFbvw=s64","userId":"09152808973096516443"}}},"source":["cascade_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_alt.xml\")"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FHKOvVjC4UTk"},"source":["###**Capturing the Video**\n","\n","We will use real-time video camera for getting the input video.\n","\n","**0** will indicate the default camera. If we are using anyother web-cam or external camera we have to give the number accordingly."]},{"cell_type":"code","metadata":{"id":"pmRfXs913Xt4"},"source":["# Getting the input from system camera\n","video_capture = cv2.VideoCapture(0)\n","\n","# Setting the width and height of the video window\n","video_capture.set(3, 640) # index 3 --> width parameter\n","video_capture.set(4, 480) # index 4 --> height parameter\n","\n","while True:\n","  # Get the next video frame \n","  ret, image = video_capture.read()\n","\n","  # Transform the image into gray scale\n","  gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","  # Use the face detection algorithm with the trained classifier\n","  detected_faces = cascade_classifier.detectMultiScale(\n","      gray_image, \n","      scaleFactor = 1.2,\n","      minNeighbors = 5,\n","      minSize = (30, 30)\n","  )\n","\n","  # Draw the rectangles around faces in every video frame\n","  for (x, y, width, height) in detected_faces:\n","    cv2.rectangle(image, (x, y), (x + width, y + height), (0, 255, 0), 3)\n","\n","  # Title of the video window\n","  cv2.imshow('Real-Time Face Detection', image)\n","\n","  # Break the loop when a key is presed: 'ESC' to quit\n","  key = cv2.waitKey(30) & 0xff\n","  if (key == 27):\n","    break\n","\n","# Destroy and release the camera\n","video_capture.release()\n","cv2.destroyAllWindows()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":350},"id":"YoK1pRC59oCn","executionInfo":{"status":"error","timestamp":1621165244066,"user_tz":-330,"elapsed":785,"user":{"displayName":"Anand G","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBkVIo1RLhOwk1a6Mzmibi2s010DdEUBbH1fsFbvw=s64","userId":"09152808973096516443"}},"outputId":"d0b69349-58ff-4f12-a55b-36b9d85cdc5f"},"source":["import numpy as np\n","import cv2\n","\n","cap = cv2.VideoCapture(0)\n","\n","while(True):\n","    # Capture frame-by-frame\n","    ret, frame = cap.read()\n","\n","    # Our operations on the frame come here\n","    # gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","\n","    # Display the resulting frame\n","    cv2.imshow('frame',frame)\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        break\n","\n","# When everything done, release the capture\n","cap.release()\n","cv2.destroyAllWindows()"],"execution_count":15,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-ee3325c9790a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Display the resulting frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xFF\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'q'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/patches/__init__.py\u001b[0m in \u001b[0;36mcv2_imshow\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \"\"\"\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m   \u001b[0;31m# cv2 stores colors as BGR; convert to RGB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'clip'"]}]}]}